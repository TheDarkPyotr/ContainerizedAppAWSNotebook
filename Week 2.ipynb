{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Fargate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/aws-fargate.png)\n",
    "\n",
    "Dal momento che ora comprendi le basi di Docker e come eseguire un contenitore Docker su un host singolare, diamo un'occhiata all'immagine più grande. L' esecuzione di contenitori su EC2 come opzione di hosting può funzionare per te. Ma è anche necessario tenere a mente tutti i pezzi che avrete bisogno di gestire quando si sceglie di farlo. Ci sono due diversi livelli che è necessario gestire quando si ospitano i contenitori. È necessario gestire le istanze EC2 per l'hosting, così come i contenitori che si posizionano su tali istanze, altrimenti noto come cluster. Eseguiremo questo processo per avere un'idea migliore. Per iniziare, è necessario eseguire il provisioning , configurare e scalare un cluster di istanze EC2. Le istanze verranno posizionate in subnet all'interno del VPC nelle zone di disponibilità. Andremo avanti e disegneremo alcune istanze nel nostro diagramma. Per il provisioning, è necessario scegliere il tipo di istanza EC2, l'AMI, e fornire qualsiasi altra configurazione EC2 che potrebbe essere necessaria, come i dati utente per l'avvio. E poiché queste istanze EC2 verranno utilizzate per ospitare contenitori Docker, sarà necessario assicurarsi che l'installazione di Docker faccia parte del processo di bootstrap. È inoltre necessario assicurarsi che queste istanze vengano continuamente applicate patch , aggiornate e valutate per la sicurezza. Avranno bisogno dei più recenti e più grandi pacchetti software per l'hosting di contenitori, quindi assicurati di avere questi processi in atto. Successivamente, sarà necessario configurare e configurare il ridimensionamento automatico EC2. Il ridimensionamento automatico eseguirà il provisioning di nuove istanze EC2 quando la domanda sui contenitori aumenta e la scalabilità automatica terminerà le istanze man mano che i contenitori vengono arrestati e pertanto richiederà meno infrastruttura di calcolo per eseguirne il backup. Una volta configurato e funzionante tutto questo, è possibile eseguire contenitori su questo gruppo di istanze EC2 o sul cluster. Ogni istanza EC2 avrà molto probabilmente più istanze contenitore in esecuzione al suo interno. Soprattutto quando si aumenta il numero di contenitori di cui si ha bisogno. Quindi ognuno di questi qui sono solo istanze di contenitore diverse sopra ogni host. Quindi abbiamo alcuni EC2 disegnati qui, ma come esattamente queste istanze del contenitore vengono posizionate sopra gli host? Questo può essere gestito utilizzando uno strumento di orchestrazione, come Amazon Elastic Container Service , o ECS, che stiamo per rappresentare qui. Discuteremo questo servizio in modo approfondito in un video successivo. Ma per ora, basta capire che ECS è il servizio con cui interagirai per eseguire e gestire i tuoi container. Non interagirai direttamente con l'host. Ora, nel corso del tempo, è necessario monitorare utilizzando strumenti come, Amazon CloudWatch, per garantire che il cluster è in scala correttamente. È inoltre possibile modificarlo in base alle esigenze per ottimizzare le risorse del cluster. Quindi, dare un'occhiata a tutto questo qui sembra essere un sacco di configurazione preliminare necessaria per ospitare contenitori in cima a EC2. La domanda diventa: come è possibile eseguire i container senza doversi preoccupare di configurare tutta questa infrastruttura? Questo è dove un servizio chiamato AWS Fargate può essere di grande aiuto. AWS Fargate è un motore di elaborazione senza server e un'opzione di hosting per carichi di lavoro basati su container. Ciò che Fargate ti consente di ospitare i tuoi container su una piattaforma di elaborazione completamente gestita. Ciò significa che nessuna infrastruttura di provisioning, nessuna configurazione della scalabilità dei cluster e nessuna gestione dei server nel tempo. AWS Fargate astrae tutto questo lontano da te. Quindi il nostro diagramma passerebbe dall'assomigliare a questo, ad apparire così. Potete vedere qui, i contenitori sono ancora distribuiti su AZ e il ciclo di vita del contenitore sarebbe ancora gestito da uno strumento di orchestrazione, o in questo caso, Amazon ECS. Tuttavia, non vi è alcuna istanza EC2 visibile in qualsiasi punto del diagramma. Questo perché è astratto da voi, consentendo di concentrare il vostro tempo ed energia progettando e costruendo le vostre applicazioni e i vostri contenitori, invece di gestire l'infrastruttura sottostante che esegue tali contenitori. Quando usi Fargate, tutto quello che devi fare è definire ciò che i tuoi contenitori devono essere eseguiti. Quindi, quello che devi configurare è, in primo luogo, quale immagine vuoi usare? È inoltre necessario configurare la quantità di memoria e vCPU necessarie al contenitore. È inoltre possibile configurare la rete, ad esempio il VBC da utilizzare , le subnet e i gruppi di protezione necessari. Infine, è anche possibile configurare tutte le autorizzazioni IAM necessarie per i contenitori. Come potete vedere da questo diagramma, l'utilizzo di AWS Fargate come piattaforma di hosting consente di gestire i contenitori e definire ciò che i contenitori devono essere eseguiti, senza doversi preoccupare dell'infrastruttura sottostante. Alcune altre cose da notare su AWS Fargate, sono che non paghi per istanza ora o secondo, come faresti con EC2. Al contrario, si paga solo quando il contenitore è in esecuzione e quando il contenitore non è in esecuzione, si smette di incorrere in spese. Continueremo a parlare di Fargate in arrivo, e eseguiremo una demo per approfondire le specifiche del lavoro con il servizio. Quindi, grazie per esserti unita a me, e ci vediamo la prossima volta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Fargate Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vedremo come eseguire un'istanza contenitore su AWS Fargate.\n",
    "Ho un'app web scritta in Python e questa app web serve semplicemente HTML statico,\n",
    "CSS e script Java.\n",
    "Voglio ospitare questo contenitore su Fargate e renderlo pubblicamente disponibile fornendolo con un bilanciamento del carico dell'applicazione. \n",
    "\n",
    "AWS Fargate ha alcuni concetti chiave che è necessario comprendere.\n",
    "Questi concetti provengono effettivamente da ***Amazon Elastic Container Service***, che è uno strumento di orchestrazione dei contenitori. \n",
    "Fargate è semplicemente il modo serverless per ospitare un contenitore utilizzando Amazon Elastic Container Service. \n",
    "\n",
    "Il primo termine da sapere è ***cluster***.\n",
    "Un cluster è un limite di isolamento logico per l'infrastruttura che ospita i contenitori.\n",
    "Questo cluster risiede all'interno della rete privata virtuale di vostra scelta e può estendersi su più zone di disponibilità.  È possibile selezionare anche le subnet in cui si desidera inserire le istanze del contenitore e Fargate provvederà a eseguire il provisioning e la gestione del cluster.\n",
    "\n",
    "Poiché questo cluster è astratto dall'utente, **non*** si dispone di accesso SSH o accesso di rete ad alcuna istanza sottostante. \n",
    "\n",
    "\n",
    "Per eseguire i contenitori, creerai quelle che vengono chiamate ***attività e servizi***.\n",
    "Questi servizi posizioneranno quindi le ***attività nel cluster***.\n",
    "Un' ***attività*** è a livello base solo un wrapper in cui eseguire i contenitori.\n",
    "Per eseguire un'attività, è necessario creare una definizione di attività.\n",
    "Una definizione di attività è una ***configurazione per il contenitore***\n",
    "o i contenitori che verranno eseguiti.\n",
    "Una definizione di attività include quali immagini e tag devono essere utilizzati,\n",
    "quanta memoria e vCPU sono necessarie per ogni contenitore, quali porte il contenitore dovrebbe essere in ascolto e tutti i volumi condivisi se sono necessari. \n",
    "\n",
    "Non è necessario che l'intero stack di applicazioni esista\n",
    "in una singola definizione di attività. E in realtà nella maggior parte dei casi non dovrebbe.L' applicazione può estendersi a più definizioni di attività combinando contenitori correlati nelle proprie definizioni di attività, ognuno dei quali rappresenta un singolo componente dell'applicazione.\n",
    "\n",
    "Una volta definita la definizione dell'attività, è necessario definire un ***servizio***\n",
    "che eseguirà effettivamente l'attività in base a tale definizione di attività.\n",
    "Un servizio consente di configurare il numero di attività in esecuzione che si desidera eseguire e gestire nel cluster. \n",
    "\n",
    "È inoltre possibile definire se eseguire o meno il servizio con un servizio di bilanciamento del carico, nonché quali subnet e gruppi di sicurezza si desidera utilizzare le attività.\n",
    "Quindi quello che stiamo per fare è creare un bilanciamento del carico dell'applicazione\n",
    "in un VPC esistente per fronteggiare il nostro servizio.\n",
    "Stiamo quindi andando a creare un cluster Fargate su due subnet nello stesso VPC esistente, creare una definizione di attività per la nostra app Web, e quindi creare un servizio per eseguire l'attività sulla parte superiore del cluster in cui vogliamo due attività in esecuzione.\n",
    "\n",
    "Il seguente comando permette la creazione del bilanciamento del carico per l´applicazione: questo ci permette di accedere all´applicazione che é in esecuzione sulla porta 8080. Vogliamo essere in grado di inviare una richiesta HTTP alla porta 80 del bilanciamento del carico dell´applicazione e far inoltrare la richista al container back-end che é in esecuzione sulla porta 8080."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***aws elbv2 create-load-balancer --name FargateLoadBalancer \\  \n",
    "--subnets subnet-ID1 subnet-ID2\\  \n",
    "--security-group -sg-GroupID --scheme internet-facing \\  \n",
    "--type-application --ip-address-type ipv4***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L´output restituto é un ARN o ***Amazon Resource Name*** del bilanciamento del carico appena creato. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo adesso un ***gruppo target*** ovvero il luogo dove verranno svolte le attivitá. Poiché i contenitori sono esposti sulla porta 8080 indichiamo per il gruppo la porta 8080. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***aws elv2 create-target-group --name FargateTargetGroup --protocol HTTP\\   \n",
    "--port 8080 --vpd-id vpc-IDVpc --target-type ip***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L´output del comando é dinuovo un ***ARN*** rispetto al gruppo target appena creato. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo adesso un ***listener*** che ascolterá sulla porta 80 le richieste HTTP in arrivo e le instraderá al gruppo target sulla porta 8080. Qui devo specificare l´ARN del bilanciamento del carico e l´ARN del gruppo target a cui inoltrare le richieste in entrata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***asw elbv2 create-listener --load-balancer-arn (ARN-Load-Balancer QUI) --protocol HTTP \\  \n",
    "--port 80 --default-actions Type=forward,TargetGroupArn=(ARN-Target-Group QUI)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo adesso il ***cluster*** che ospiterá le nostre attivitá: chiameremo l´API di creazione del cluster e gli daremo un nome (fargate-cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***aws ecs create-cluster --cluster-name fargate-cluster***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato é ancora un ***ARN*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso creaiamo la definizione di ***attivitá*** ovvero la configurazione per il nostro container.Le attivitá hanno associato le regole IAM (Identity and Access Management) per l´esecuzione del comando devono essere giá precedentemente definite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***aws ecs register-task-definition --family python-web-app --task-role-arn (ARN IAM Task  role QUI)--execution-role-arn (ARN IAM QUI) --network-mode aswvpc --container-definitions (PATH al .JSON del container fargate) --cpu .5vCPU --memory 1GB --requires-compatibilities FARGATE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per eseguire il comando devo spostarmi nella stessa directory del file ***fargate-container.json*** tuttavia prima analizziamolo: \n",
    "![title](images/fargate-container.js.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel file dobbiamo specificare l´ARN del nostro repository su ***ECR*** (Elastic Container Registry) prendendo l´URI dalla lista (andando nella console AWS). Eseguiamo il comando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che il nostro ***task*** è definito,creeremo un ***servizio*** che utilizza tale definizione di attività per avviare un'attività.\n",
    "Avrò bisogno di fornire l'ARN per questo cluster.\n",
    "Avrò anche bisogno di fornire la definizione dell'***attivitá ARN*** e quindi posso copiarlo e incollarlo e usarlo da sopra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***aws ecs create-service --cluster (QUI ARN CLUSTER) --service-name FargateDemoService2 --task-definition (QUI ARN TASK DEFINITO) --load-balancers (QUI PATH load-balancer.json) --desired-count 2 --launch-tpe FARGATE --network-configuration (PATH task-networking.json) --scheduling-strategy REPLICE --deployment-controller type=ECS***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L´ARN del task ci é data dall´output del comando precedente, dunque copy and paste. Analogo per l´ARN del cluster. Nel comando sto indicando la creazione di 2 task e sto fornendo il file ***load-balancer.json*** che collega questo servizio al bilanciamento del carico creato in precedenza. Il file é definito cosí:\n",
    "![title](images/load-balancer.png)\n",
    "Indichiamo nel file load-balancer.json l´ARN del guppo target creato in precedenza.  \n",
    "Indichiamo come ***launch-type*** FARGATE perché useremo ECS per lanciare il task sul ***Cluster Fargate.***  \n",
    "Il contenuto del file ***task-networking.json*** specifica le subnets di riferimento (utilizzate anche nel primo comando con subnet-ID1 e subnet-ID2) e il gruppo di sicurezza (indicato sempre nel primo comando come GroupID). \n",
    "![title](images/task-networking.png)  \n",
    "Una volta inseriti tutti i parametri necessari nel comando si invii: l´output indicherá la corretta creazione del nostro servizio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il seguente comando restituisce i servizi di AWS ECS sul cluster Fargate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***aws ecs list-services --cluster fargatecluster***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tutto é stato eseguito correttamente é possibile verificare le i nostri due task sono operativi su quel cluster. Dalla console AWS, sezione bilanciamento del carico in EC2 (EC2 > Load Balancing) é possibile prendere il nome DNS del bilanciamento del carico. Teoricamente dovremmo essere in grado di accedere a questi task attraverso questo nome DNS. Incollando l´URL del DNS nel browser dovremmo poter visualizzare correttamente la nostra applicazione web python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container Networking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprio come nessun uomo è un'isola, nessun container o compito è un'isola. \n",
    "Spesso, potrebbe essere necessario il traffico da Internet per colpire (***raggiungere***) i singoli contenitori seduti su istanze EC2 o si può desiderare che i contenitori siano in grado di comunicare con altri contenitori. Comunque, risolveremo entrambi questi problemi di seguito. \n",
    "\n",
    "Quindi iniziamo con il ***primo problema. Come facciamo arrivare il traffico alle nostre task?***\n",
    "La risposta è semplice. Proprio come avremmo ottenuto il traffico verso un server o una macchina virtuale, abbiamo bisogno di un ***bilanciamento del carico***. \n",
    "In AWS, offriamo la famiglia Elastic Load Balancer composta da tre diversi tipi di bilanciamento del carico tra cui scegliere: il ***bilanciamento del carico di rete***, il ***classico bilanciamento del carico*** e il ***bilanciamento del carico dell'applicazione***. \n",
    "Il bilanciamento del carico su cui ci concentreremo principalmente è il ***bilanciamento del carico dell'applicazione*** o ***ALB***, in quanto offre la più ampia gamma di funzionalità per i carichi di lavoro dei container. Una di queste funzionalità è la possibilità di utilizzare la ***mappatura dinamica delle porte host*** che consente di posizionare più task dello stesso servizio su una singola istanza contenitore. Senza il mapping dinamico delle porte host, se si dispone di un servizio con due attività, è necessario posizionarle su due istanze EC2 separate perché i contenitori non possono essere eseguiti sulla stessa porta sullo stesso server. \n",
    "\n",
    "La mappatura dinamica delle porte host consente di aggirare questo problema e può essere una caratteristica estremamente vantaggiosa dell'ALB. ALB è il servizio di bilanciamento del carico consigliato da utilizzare in qualsiasi momento è necessario bilanciare il carico delle richieste HTTP o HTTPS. È anche altamente integrato nei servizi di container AWS come ECS, sia che stiate posizionando contenitori su istanze EC2 o utilizzando il tipo di lancio di Fargate. In effetti, ECS configurerà il bilanciamento del carico per conto dell'utente e posizionerà i task sulle istanze del cluster. Una volta posizionato un task su una macchina, configurerà anche il bilanciamento del carico per inviare il traffico al nuovo task senza alcun intervento manuale.\n",
    "Un altro utile vantaggio dell'ALB è che può eseguire il ***routing basato sul percorso*** che è un modo elegante di dire che può instradare le richieste in base all'URL. \n",
    "![title](images/routing-based-path.png) \n",
    "\n",
    "Ad esempio, in questo diagramma, abbiamo tre diversi percorsi URL per il nostro traffico da colpire. Un percorso colpisce il servizio utenti, uno colpisce il servizio argomenti e uno colpisce il servizio messaggi. Pertanto, se un utente digita il percorso URL del servizio utenti, il servizio di bilanciamento del carico dell'applicazione inoltrerà tale richiesta ai contenitori che supportano tale servizio. Quindi il bilanciamento del carico è la risposta al primo problema che abbiamo avuto. Abbiamo capito come portare il traffico alle nostre attività sulle nostre istanze. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ora il ***secondo problema. Vogliamo che i nostri container siano in grado di comunicare con servizi esterni**8. Questo problema viene risolto attraverso la ***definizione del task***. \n",
    "Nella definizione dell'attività, è possibile specificare la modalità di rete Docker che ECS utilizzerà per i contenitori dell'attività. Sono disponibili ***quattro diverse opzioni di modalità di rete*** che è possibile specificare nella definizione dell'attività. \n",
    "1. La prima modalità ***none***: non permette ai tuoi container di parlare con niente o con nessuno. Inoltre, non consente di specificare alcun mapping di porte. \n",
    "2. La seconda modalità di rete è ***bridge***. Questa è anche la modalità predefinita e utilizza la rete incorporata di Docker. Ogni task ottiene il proprio IP privato e utilizza il bridge Docker per qualsiasi comunicazione. In questa modalità, i contenitori condivideranno la stessa interfaccia di rete dell'istanza EC2 host. \n",
    "3. La terza modalità è ***host***. Questa modalità elimina la necessità della rete virtuale incorporata di Docker perché le porte contenitore sono mappate direttamente nell'interfaccia di rete dell'istanza EC2. Una cosa da prestare attenzione nella modalità host è che ***non è possibile sfruttare la mappatura dinamica delle porte host*** in quanto questa modalità non consente più task dello stesso servizio di essere posizionate su una singola istanza contenitore. \n",
    "4. La quarta modalitá, la modalità ***AWS VPC***: questa modalità offre le prestazioni di rete più elevate per i contenitori perché a ogni attività vengono assegnate le stesse proprietà di rete delle normali istanze EC2. Ciò significa che ad ogni task viene data la propria interfaccia di rete elastica, il proprio IP privato e un nome host DNS interno. Uno svantaggio è proprio come la modalità host, inoltre ***non consente la mappatura dinamica delle porte host.*** Tuttavia, in generale, questa modalità offre un maggiore controllo sul modo in cui si desidera che i contenitori comunichino con altri servizi e semplifica l'idea della rete dei contenitori.  Se la definizione dell'attività utilizza questa modalità di rete AWS VPC, ***è necessario utilizzare un VPC, subnet e gruppi di sicurezza per i contenitori***. Tuttavia, questa è una buona cosa in quanto fornisce un maggiore livello di sicurezza per i contenitori e consente di sfruttare gli strumenti che monitorano i contenitori a un livello più granulare. In genere, questo è l'approccio consigliato quando si lavora con i task in quanto consente di trattare ogni contenitore come un'istanza EC2 con funzionalità di rete complete del VPC e fornisce anche la potenza di rete maggiore rispetto a tutte le altre modalità. Tenere presente che tutto questo viene deciso attraverso la definizione del task per garantire che i task abbiano tutto ciò di cui hanno bisogno per comunicare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratteremo adesso della casistica in cui un contenitore ha bisogno di salvare i file in una sorta di archiviazione persistente. La prima cosa che dovresti sapere è ***per impostazione predefinita, lo storage utilizzato dai contenitori non è persistente***. \n",
    "I file salvati nel livello scrivibile del contenitore sono per natura ***effimeri***.Se condividere i dati o semplicemente avere persistenza tra le istanze di una particolare immagine contenitore, questo è qualcosa che può essere raggiunto. \n",
    "Ma prima di parlare delle soluzioni, diamo un'occhiata a importanti tecnologie utilizzate che entreranno in gioco con lo storage persistente. Le immagini sono costituite da livelli impilabili che aiutano a implementare le modifiche in modo rapido ed efficace. I livelli immagine si combinano con un livello contenitore superiore scrivibile per creare quello che chiamiamo contenitore. Quando un contenitore viene rimosso, è il livello superiore scrivibile che viene rimosso lasciando dietro i livelli immagine sottostanti. Come risultato dell'utilizzo di copy-on-write per il livello scrivibile superiore, quando il contenitore viene rimosso, i dati associati vengono persi. \n",
    "Per avere dati persistenti con contenitori, ***i dati devono essere esternalizzati e persistenti all'esterno del contenitore e non applicati come livello contenitore***. \n",
    "Quindi e' questo il problema. Qual è la soluzione? \n",
    "Beh, ci sono un paio di opzioni di cui voglio parlare. Il primo é un ***mount*** in breve è un file o una cartella memorizzata in qualsiasi punto del file system host contenitore e montato in un contenitore in esecuzione. Quando si utilizza un mount, è necessario impostare il ***flag di mount*** quando si esegue un nuovo contenitore e specificare la cartella di origine sull'host contenitore. \n",
    "\n",
    "La seconda opzione è usare i ***volumi***. I volumi vengono archiviati anche dal file system host, ma sono completamente gestiti dall'agente contenitore. I supporti, d'altra parte, possono effettivamente essere modificati da processi al di fuori della gestione dei container. ***I volumi utilizzano ancora il flag di montaggio per specificare il volume da montare su un nuovo contenitore.*** Invece di specificare una directory locale, è necessario specificare il nome del volume che si desidera montare nel contenitore. \n",
    "\n",
    "In termini di metodo preferito, dovresti andare con i volumi. I mount forniscono un modo semplice per accedere ai file sottostanti dall'host, ma i dati non vengono inizializzati ed è comune incorrere in problemi di autorizzazione. I volumi rendono ancora più semplice l'accesso ai dati persistenti sull'host sottostante, ma i problemi di autorizzazione sono molto meno comuni e i volumi forniscono la possibilità aggiuntiva di accedere a sistemi di storage non locali come i mount NFS. \n",
    "\n",
    "In AWS, voglio sottolineare che se stai utilizzando i volumi Amazon Elastic Block Store o EBS per lo storage host sottostante, i volumi EBS sono specifici per le zone di disponibilità e non possono essere montati su AZs o su più istanze Elastic Compute Cloud contemporaneamente. Se si tenta di condividere l'accesso al volume tra contenitori, è necessario che i contenitori si trovino sulla stessa istanza sottostante, altrimenti il volume deve essere clonato utilizzando un'istantanea EBS e quindi creare un nuovo volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
