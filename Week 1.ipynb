{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers described"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La containerizzazione è diventata una grossa parola di recente. Ma cosa intendiamo veramente quando parliamo di container? E anche se tutti sono desiderosi di immergersi in profondità nei container, è importante innanzitutto capire cosa differenzia i contenitori da altri tipi di virtualizzazione. Iniziamo con alcuni dei concetti di base della virtualizzazione. Quando diciamo containerizzazione o contenitori, ci riferiamo alla virtualizzazione a livello di sistema operativo. Mentre i server virtuali come Amazon Elastic Compute Cloud e la containerizzazione sono entrambi modi per disaccoppiare i carichi di lavoro dall'hardware sottostante, esistono alcuni modi chiave in cui differiscono. In una tipica macchina virtuale o VM, ad esempio EC2, la virtualizzazione sta imitando un ambiente hardware. Ogni VM dispone del proprio sistema operativo, delle risorse e di tutti i componenti interni necessari a qualsiasi strumento o applicazione in esecuzione sulla VM. Mentre questo fornisce un grande controllo, spesso c'è uno spreco in quanto ogni VM, anche se esegue istanze identiche della stessa applicazione o strumento, dovrà avere il proprio sistema operativo completo e l'allocazione hardware condivisa dall'host. Con la containerizzazione, c'è un ulteriore livello di virtualizzazione sopra il sistema operativo guest. I diversi contenitori virtualizzati possono condividere un sistema operativo sottostante e anche cose aggiuntive come file binari e driver per ridurre il sovraccarico operativo. Per questo motivo, un contenitore è in grado di eseguire un'istanziazione molto più leggera dei soli componenti necessari e a sua volta ha molto meno duplicazioni e sprechi rispetto alle VM. Proprio come per le macchine virtuali, è comunque possibile ottenere l'isolamento dell'ambiente applicativo e la dedizione delle risorse sottostanti. Hai il pieno controllo su come ottenere l'accesso ai singoli contenitori e sul livello di utilizzo delle risorse a cui ciascun contenitore ha accesso. Ciò rende la replica, il backup e il ripristino, la distribuzione e l'utilizzo delle risorse sottostanti più semplici e facili da gestire, poiché le immagini dei contenitori sono più incentrate su ciò di cui hanno bisogno invece di ogni dipendenza sottostante. La containerizzazione porta anche con sé alcune terminologie cruciali di cui è necessario essere consapevoli. Questi termini sono contenitore, immagine e Registro di sistema. Un contenitore è il pacchetto complessivo e l'ambiente virtualizzato che useresti. Le applicazioni verranno eseguite all'interno dei contenitori. Tutto ciò di cui un'applicazione ha bisogno verrebbe inserito nel contenitore dalle dipendenze alle variabili di ambiente. E' tutto confezionato all'interno del contenitore. Molto simile all'utilizzo di una macchina virtuale, come EC2, l'utilizzo di un contenitore consente di isolare e configurare l'ambiente specifico per l'applicazione che si desidera eseguire. Ogni diversa applicazione che si desidera isolare avrebbe un proprio contenitore. Per avviare un contenitore, è necessario innanzitutto definire tutto ciò che si desidera all'interno del contenitore, come dipendenze , codice sorgente e configurazioni. Acquisisci questa definizione in qualcosa chiamato dockerfile. Puoi quindi prendere questo file dockere costruirlo in un'immagine. Un' immagine contenitore è simile a un'immagine EC2, sono la configurazione pacchettizzata che ti servirà per avviare o distribuire il tuo contenitore in esecuzione. È essenzialmente un progetto per il tuo contenitore. Spesso, l'immagine conterrà solo l'applicazione, in modo che quando viene distribuita il contenitore occupi una piccola quantità di spazio sul disco e si avvii rapidamente. Le immagini create per eseguire i contenitori verranno memorizzate in qualcosa chiamato registro. Un registro è molto simile a un repository di codice sorgente. Un Registro di sistema viene utilizzato specificamente per contenere immagini contenitore completamente compilate. In questo modo quando arriva il momento di eseguire l'immagine del contenitore, non è necessario compilare, è già compilato e memorizzato nel registro. Le opzioni del Registro di sistema disponibili con AWS sono Docker Hub, che consente di archiviare immagini private e pubbliche che si desidera utilizzare, nonché ECR o Amazon Elastic Container Registry. Questo ti permetterà di archiviare le tue immagini con un servizio gestito su cui puoi fare affidamento. È possibile condividere immagini con altri utenti dell'organizzazione e distribuire contenitori dalle immagini in ECR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to take a look at the basic components of Docker to get a better idea of how it all works. Docker has 3 main components. ***The Docker daemon. The Docker CLI. And the image registry.*** We'll be talking about\n",
    "each of these components but we'll start with the Docker client first. \n",
    "The ***Docker client*** provides developers a way to interact with Docker through a Command Line Interface or CLI. This is how you issue commands to Docker to build your containers, run your containers, or stop your containers. When you use the CLI you'll type a command into your terminal that starts with Docker. For instance, if you want\n",
    "to stop your containers you would run the Docker stop command. Through the Docker client,\n",
    "Docker provides commands to manage the complete lifecycle of your containers. Such as docker create,\n",
    "that creates a container but does not start it. Docker run, which creates and starts a container in one operation. And docker rm, that deletes a container. \n",
    "\n",
    "![title](images/s1.png)\n",
    "\n",
    "The next thing you need is for Docker to listen to those commands and perform them for you. This is where the second component, the ***Docker daemon*** comes into play. The Docker daemon is installed on a host machine and essentially acts as the brain of the Docker; that creates and manages your Docker images on your behalf. Its whole purpose is to perform the commands that the client issues. So, if you issue the Docker stop command for a particular container, the daemon will go ahead and find that container and stop it. \n",
    "Also, any time your container needs access to network ports, storage volumes, or any other components at the operating system level, the Docker daemon will provide that. \n",
    "\n",
    "Finally, the third piece of the puzzle is the ***image registry***. Just like a source code repository is a place to store your code. The image registry is a place to store your Docker images. The image registry allows you to push and pull your container images as needed. Registries can be either public, where images are shared\n",
    "with the whole world. Or, registries can be private. Where your images are only shared amongst members of an\n",
    "enterprise or a team. A registry makes it possible for the Docker daemon to retrieve and run your Docker images. So, what is a Docker image you might ask? Well you've probably caught on by now that we're not talking\n",
    "about the type of containers that you buy at a container store. \n",
    "We're talking about thecontainers that you build. Just like you would,say, build a building. And when you build a\n",
    "building or a container, you need blueprints. In the container world, these blueprints are called ***Docker images***. Which are lightweight executable packages that include everything you need in it. All of your application code, software, dependencies, and config variables. They are considered read only artifacts. So once a container is built it cannot be changed unless you build a new image. And just as we mentioned earlier. You put these Docker images in image registries. So now that we have a Docker image that is stored in a registry, how do we get that image to be a container running on a Docker host? \n",
    "To do this you need to issue the command Docker run through the Docker CLI. The Docker client will then delegate that command to the daemon. Docker run is a magical command that takes care of everything you need to start up a container. The first thing the daemon does, in response to the command, is check to see if the\n",
    "appropriate image exists on the Docker host. If it doesn't it downloads it from the image registry and spins up the Docker container on the Docker host, using that image. When you use the CLI to do a Docker run command on a particular image it results in a container.\n",
    "\n",
    "![title](images/s3.png)\n",
    "A ***container is simply just a running instance of a Docker image***. You can think of it as an encapsulated environment to run your applications that only has access to the resources that are provided in the Docker image. So how do we get the image in the first place? That would be through\n",
    "something called a Docker file. ***A Docker file is a plain text, standardized template, that you create with instructions that informs Docker how your Docker image should get built. It's a script that contains a list of commands that the Docker client will call when putting your image together.*** It includes instructions for installing the operating system, any other relevant software, and making sure all the necessary dependencies are in place for your container to run properly. When you use the Docker build command through the CLI, on a particular Docker file, it results in a Docker image. \n",
    "\n",
    "Now that we have all the pieces lets quickly summarize this. You start with a Docker file and list out everything you need for your container. The operating system, the software, and any other necessary information. When you build a Docker file it results in a Docker image. Which is just a lightweight executable package. When you run that executable using that Docker run command it then results in a container on a Docker host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker files and semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diamo un'occhiata più da vicino a come costruite i vostri contenitori usando i file Docker. Come sappiamo, per avere un'applicazione eseguita con successo, è necessario molto di più del semplice codice sorgente. È necessario assicurarsi che l'ambiente di runtime sia installato, che vengano scaricate tutte le dipendenze, vengano creati file di configurazione , esistano variabili di ambiente e potenzialmente in esecuzione altri processi di cui l'applicazione ha bisogno. \n",
    "Quindi, per creare un ambiente di esecuzione portatile e autonomo per la tua app, come un contenitore Docker, devi catturare tutto ciò di cui l'app ha bisogno e costruirlo tutto in un'immagine. \n",
    "Per creare un'immagine, è necessario creare quello che viene chiamato file Docker. Un file Docker è essenzialmente un insieme di istruzioni su come costruire un contenitore passo dopo passo. \n",
    "Quando è il momento di costruire il contenitore, ogni costruzione viene eseguita per formare un'immagine contenitore eseguibile. Esistono diverse parole chiave che Docker utilizza per le istruzioni. Per avere un'idea di come funziona e quali parole chiave esistono, diamo un'occhiata a un file Docker molto semplice.\n",
    "Per iniziare, ho intenzione di aprire l'IDE basato su cloud chiamato AWS Cloud9. Puoi vedere che ho già effettuato l'accesso alla console AWS e ho intenzione di navigare su Cloud9 e aprire il mio ambiente esistente che ho già creato. \n",
    "Quindi digita ***Cloud9***, seleziona quel servizio e da qui aprirò il mio IDE esistente. C' è del codice che è già stato scritto all'interno di questa cartella python-webapp, e questa applicazione è scritta in Python e tutto ciò che fa è rendere semplice HTML statico usando un server web chiamato Flask. Lo script che esegue il rendering di questo HTML si trova qui nel file app.py. Ho intenzione di eseguire rapidamente questo file app.py dalla riga di comando in modo che possiamo vedere l'applicazione che stiamo cercando di catturare all' interno di questo contenitore. Quindi ho intenzione di andare avanti ed eseguire python3 app.py. E la nostra applicazione è ora attiva e funzionante. \n",
    "Posso visualizzare in anteprima questa applicazione selezionando Anteprima, Anteprima applicazione in esecuzione, e da qui ho intenzione di sbattere fuori in una nuova finestra. E questo è il nostro file HTML statico che ha alcuni dati fittizi. Quindi, è fantastico, ma quello che voglio fare è catturare questo codice sorgente, tutte le sue dipendenze, tutta la sua configurazione e costruirlo in un'***immagine contenitore***. \n",
    "Per fare ciò, ho bisogno di creare un file Docker che è dove vanno le istruzioni. Esaminiamo questo file Docker che ho già scritto che mostra alcune delle parole chiave che dovrai conoscere. \n",
    "\n",
    "![title](images/dockerfile1.png)\n",
    "\n",
    "\n",
    "La prima parola chiave che abbiamo è l'istruzione ***From***. \n",
    "Da è la prima istruzione Docker non comune in qualsiasi file Docker. L' istruzione From imposta l'immagine di base da cui stiamo andando a costruire sopra. Le immagini Docker possono essere sovrapposte l'una sull' altra, di cui parleremo più avanti. Le immagini di base possono essere come quello che vediamo qui. Ubuntu, che è un sistema operativo. Questo ci permette di avere un contenitore che ha una versione minima del sistema operativo Ubuntu installata indipendentemente da quale sia il sistema operativo della macchina host. Nel nostro esempio qui, puoi vedere gli stati di istruzione FROM ubuntu:16.04. Il: 16.04 sta specificando il tag o la versione di quella particolare immagine. Se si lascia fuori il tag, quando viene creata l'immagine Docker, si suppone che si desideri l'ultima versione di quell'immagine. Un punto di partenza semplice è quello di estrarre un'immagine di base da un repository pubblico che fornisce il sistema operativo o il runtime minimo necessario. Tuttavia, è anche possibile utilizzare immagini personalizzate come immagine di base. La cosa grandiosa delle immagini di base è che se hai bisogno dello stesso set di strumenti su più contenitori, puoi catturarlo in un'immagine e utilizzarlo come immagine di base ovunque sia necessario. Riducendo così la necessità di istruzioni duplicate in tutti i file Docker. \n",
    "\n",
    "La prossima è l'istruzione del manutentore o ***MANTAINER***. Questo è semplice. Questo ti permette solo di impostare chi è l'autore del file Docker.\n",
    "\n",
    "Successivamente sul nostro file Docker vediamo l'istruzione Esegui seguita da alcuni comandi. L' istruzione ***Run*** eseguirà qualsiasi comando definito in una shell. Il comando che vediamo qui è in esecuzione apt-get update e quindi apt-get install. Per installare sia pip che Python che è necessario perché Python è la lingua in cui è scritta l'app e pip è necessario per scaricare le dipendenze per l'app Python. L' istruzione Esegui è flessibile in quanto consente di eseguire i comandi necessari per l'applicazione e il contenitore. Quindi, a seconda di cosa stai cercando di fare, avresti bisogno di comandi diversi per soddisfare il tuo caso d'uso. È inoltre possibile utilizzare l'istruzione Esegui più volte in un file Docker per ottenere il risultato desiderato. La riga successiva ha l'istruzione ***COPY***. Ciò consentirà di copiare i file dalla macchina su cui si sta costruendo il file Docker nell'immagine. In questa riga, stiamo copiando un file di testo chiamato requirements.txt che è necessario per specificare le dipendenze per la nostra app web. E stiamo copiando questo file nella directory dell'app all'interno dell'immagine. Successivo è l'istruzione WORKDIRECTORY che imposterà la directory di lavoro per le istruzioni successive che verranno eseguite. Se la directory WORKING non esiste, verrà creata. Qui stiamo solo cambiando la directory di lavoro per essere la directory/app. Successivamente abbiamo un'altra istruzione ***RUN***. Questa volta stiamo usando pip per installare le dipendenze per la nostra app. Poi abbiamo un'altra istruzione COPY. Questo sta per copiare tutto il codice sorgente per il nostro semplice sito web nella directory/app. La prossima istruzione che abbiamo è l'istruzione ***EXPOSE***. \n",
    "Questo sta per esporre una porta per il contenitore su cui comunicare. Se si desidera che il contenitore sia in grado di comunicare con entità esterne come altri contenitori o servizi remoti, è necessario includere l'istruzione di esposizione per definire quale porta il contenitore sarà in ascolto. Quindi, in questo esempio, ho intenzione di esporre la porta 8080 per l'app web. Sul prossimo c'è l'istruzione ***ENTRYPOINT***. \n",
    "Questa istruzione consente di definire quale script o comando si desidera eseguire all'avvio del contenitore. Nel nostro esempio, stiamo chiamando Python come punto di ingresso. Finalmente abbiamo l'istruzione COMMAND. L' istruzione ***COMMAND*** è simile all'istruzione ENTRYPOINT ad un livello elevato. \n",
    "Questa istruzione consente di eseguire comandi o script in fase di esecuzione. La differenza è che l'istruzione COMMAND consente di fornire valori predefiniti, che nel nostro caso qui abbiamo definito come app.py che eseguirà lo script che avvia la nostra app. E puoi quindi passare valori tramite la riga di comando per sovrascrivere i valori predefiniti in fase di esecuzione. ***Quindi la differenza tra ENTRYPOINT e COMMAND è che COMMAND ti dà la possibilità di sovrascrivere ciò che viene eseguito in fase di esecuzione. Mentre ENTRYPOINT non può essere sovrascritto in fase di esecuzione ed è statico una volta definito.***\n",
    "\n",
    "Ci sono altre parole chiave Docker che ti saranno utili a seconda del risultato desiderato. Abbiamo almeno coperto le basi per ora, ma questa non è l'elenco completo delle istruzioni. Consulta le note sulla classe per un elenco completo delle parole chiave Docker e ulteriori informazioni sui file Docker. Continueremo a parlare e a lavorare con i file Docker in arrivo. Imparerai come utilizzare effettivamente un file Docker per creare un'immagine e quindi eseguire il contenitore da tale immagine. Quindi rimanete sintonizzati e vi vedremo nel prossimo video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker Images: Union File Systems and Copy on Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che sai cos'è un file Docker e che tipo di istruzioni puoi includere nel tuo file Docker, parliamo di come Docker costruisce, archivia ed esegue effettivamente i contenitori Docker. \n",
    "\n",
    "Quando si acquisisce un file Docker e si crea un'immagine, ogni istruzione nel file Docker crea quello che viene chiamato ***layer***. I livelli sono solo file generati dall'esecuzione di un comando. Questi livelli sono di ***sola lettura***, il che significa che non possono essere modificati. E sono impilati insieme per costruire immagini contenitore. Per capire davvero questa idea, costruiamo un file Docker e vediamo cosa succede. Quindi, come puoi vedere qui, sono già operativo e connesso alla mia istanza Cloud9. E ho gia' recuperato il file Docker che abbiamo esaminato nell'ultimo video. Per prima cosa quello che ho intenzione di fare è cambiare le directory nella directory che ha il mio file Docker. Quindi ho intenzione di solo CD nella mia app web Python. Puoi vedere qui, vado a questa cartella dell'app web Python e il file Docker si trova in quella cartella. E poi da lì, eseguirò Docker build -t, nominando l'immagine pythonwebapp e poi dot perché siamo già in quella cartella. E come puoi vedere qui, ogni istruzione che viene eseguita verrà eseguita in ordine. Si può vedere dall'output del comando che abbiamo appena eseguito, questo sta eseguendo ogni istruzione in ordine. Potete vedere qui, passo otto, nove, dieci. \n",
    "***Ogni istruzione che viene eseguita è potenzialmente la creazione di un livello o l'utilizzo di un livello esistente se questa immagine è stata creata prima o se esiste già sull'host.*** Quindi, ora che l'immagine è terminata, eseguiamo il comando Docker ispezionare per visualizzare i diversi livelli che abbiamo. Quindi eseguirò l'ispezione della finestra mobile, e poi andrò avanti e afferrerò l'ID per l'immagine. E qui potete vedere che abbiamo otto livelli elencati per questa immagine. Ogni livello è essenzialmente un dif da un'istruzione all'altra. Ogni livello che viene creato è di sola lettura e quindi impilato insieme per costruire l'immagine che funge da modello per la creazione del contenitore. ***Poiché ogni livello è indipendente e quindi impilato insieme per formare l'immagine, tutti i livelli comuni esistenti tra le immagini possono essere condivisi e non devono essere duplicati.*** Quindi, se ho creato un altro file Docker che usava anche l'immagine di base Ubuntu, condividerebbe quel livello di base. Non scaricare o creare una nuova copia. Ciò significa che l'immagine occupa meno spazio sul disco, poiché riduce al minimo la duplicazione. Docker utilizza quello che viene chiamato un ***Union File System*** per l'archiviazione efficiente di questi livelli. O quello che potresti pensare come gli elementi costitutivi per il tuo contenitore. Un file system di unione consente di ***sovrapporre più livelli*** in modo che appaiano come una vista unificata al contenitore. Se un file presente in un livello inferiore viene modificato da un livello superiore, il contenitore utilizzerà il file modificato, che proviene da una copia che è stata fatta nel livello di modifica. Non la copia originale dal livello inferiore. Come accennato in precedenza, le immagini sono di sola lettura. Quindi, che dire quando un processo o un'applicazione in esecuzione in un contenitore deve modificare un file? \n",
    "\n",
    "\n",
    "![title](images/unionfs.png)\n",
    "\n",
    "Bene, quando un contenitore viene eseguito da un'immagine, tenendo presente l'idea dei file system unione, Docker monta un ***livello scrivibile*** sopra i livelli inferiori di sola lettura. Questo livello scrivibile consente a tutti i processi o applicazioni in esecuzione all'interno del contenitore di modificare o creare file. Ad esempio, se si desidera modificare un file che esiste in un livello inferiore, il file verrà copiato dal livello di sola lettura nel livello scrivibile e modificato lì. La versione di sola lettura del file rimarrà invariata ma ora è nascosta sotto la copia nel livello scrivibile. Questa è chiamata ***strategia copy-on-write***. Utilizzando la strategia di copia in scrittura, tutti i livelli di sola lettura dell'immagine rimangono invariati, il che significa che possono essere condivisi da più istanze di contenitore in esecuzione diverse. Questa condivisione tra immagini aiuta a promuovere dimensioni di immagini più piccole. Quindi l'immagine è condivisa, ma ogni contenitore ottiene il suo livello superiore scrivibile. Questo livello superiore scrivibile rimane relativamente piccolo portando i dati nel livello scrivibile solo quando è necessario. Per impostazione predefinita, tutti i file creati in un contenitore vengono memorizzati in questo livello contenitore scrivibile. Ciò significa che se si dovesse rimuovere un contenitore, anche tutti i dati nel livello scrivibile andrebbero persi. Quindi, se stai cercando di memorizzare dati temporanei o graffiati, la natura effimera del livello scrivibile potrebbe non avere troppa importanza. Ma se vuoi dati persistenti, se vuoi condividere dati tra contenitori, dovresti assicurarti di usare qualcosa chiamato ***volumi Docker***. E i volumi esistono al di fuori del ciclo di vita del contenitore ed è gestito da Docker. Quindi, quando si rimuove un contenitore, non rimuove anche tutti i dati nel volume. Parleremo di più sullo stoccaggio persistente con i contenitori più avanti nel corso. Quindi andiamo avanti e riassumiamo ciò che abbiamo imparato. Quando si crea il file Docker, ogni istruzione nel file Docker crea un livello. E questi livelli vengono quindi impilati insieme per creare immagini contenitore. Ogni livello è di sola lettura e viene condiviso tra le immagini quando esistono livelli comuni. Quando un contenitore viene eseguito da un'immagine, viene aggiunto un livello scrivibile in alto, dove i file possono essere modificati. Docker utilizza un file system di unione e la strategia di copia in scrittura per gestire i layer in modo efficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/dockercs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
